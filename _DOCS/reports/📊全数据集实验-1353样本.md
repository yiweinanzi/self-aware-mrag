# 📊 MRAG-Bench 全数据集实验 - 1353样本

**实验开始**: 2025-10-31 12:03  
**实验状态**: 🔄 启动中...  
**数据集**: MRAG-Bench 完整数据集  
**样本数**: 1353样本  

---

## 🎯 实验配置

### 测试方法（7个）
1. **Self-Aware-MRAG** (Our Method) - EM 62.0% (100样本验证)
2. **Self-RAG** - Adaptive Retrieval + Reflection
3. **mR²AG** - Multi-Round Retrieval + Hierarchical Scoring
4. **VisRAG** - BGE Reranker
5. **REVEAL** - Two-stage Reasoning
6. **MuRAG** - FiD Parallel + Voting
7. **RagVL** - MLLM Reranker

### 评测指标（7个）
1. **EM** (Exact Match)
2. **F1** (Token-level F1)
3. **Recall@5** (Retrieval Recall)
4. **VQA-Score**
5. **Faithfulness**
6. **Attribution Precision**
7. **Position Bias Score**

---

## ⏱️ 预估时间

### 基于100样本测试的速度估算

| 方法 | 100样本速度 | 1353样本预估 |
|------|------------|-------------|
| Self-Aware-MRAG | 27秒/样本 | ~10.1小时 |
| Self-RAG | ~30秒/样本 | ~11.3小时 |
| mR²AG | ~35秒/样本 | ~13.2小时 |
| VisRAG | ~40秒/样本 | ~15.0小时 |
| REVEAL | ~30秒/样本 | ~11.3小时 |
| MuRAG | ~45秒/样本 | ~16.9小时 |
| RagVL | ~50秒/样本 | ~18.8小时 |

**总预估时间**: ~96小时（约4天）

**优化效果**:
- Self-Aware-MRAG的Adaptive Retrieval可节省约40%样本的检索时间
- 实际可能更快（部分简单样本推理更快）

---

## 📋 实验日志

**日志文件**: `/root/autodl-tmp/full_dataset_experiment.log`

**监控命令**:
```bash
# 查看进度
tail -50 /root/autodl-tmp/full_dataset_experiment.log | grep -E "(运行|完成|%)"

# 查看当前方法
tail -100 /root/autodl-tmp/full_dataset_experiment.log | grep "评测方法"

# 实时监控
tail -f /root/autodl-tmp/full_dataset_experiment.log
```

---

## 🔍 当前进度

### 初始化阶段
- [x] 实验启动 (12:03)
- [x] 配置加载
- [ ] 数据集加载中... (1353样本)
- [ ] 模型初始化
- [ ] Self-Aware-MRAG开始

### 方法进度
- [ ] Self-Aware-MRAG (0/1353)
- [ ] Self-RAG (0/1353)
- [ ] mR²AG (0/1353)
- [ ] VisRAG (0/1353)
- [ ] REVEAL (0/1353)
- [ ] MuRAG (0/1353)
- [ ] RagVL (0/1353)

---

## 📊 Self-Aware-MRAG 最佳配置

基于100样本验证的最优配置：

```python
# Context格式
doc_text = doc[:512] if len(doc) > 512 else doc

# 生成参数
answer = self.qwen3_vl.generate(
    text=prompt,
    image=image,
    max_new_tokens=10,
    temperature=0.01
    # 注意：不设置 do_sample
)

# 关键参数
- Position Fusion: np.exp(-np.arange(k) * 0.5)  # 修复版
- Top-K文档: 3
- Query Reformulation: 启用
- Attribution: 启用
- uncertainty_threshold: 0.35
```

**100样本性能**:
- EM: 62.0%
- F1: 67.72%
- VQA: 20.67%
- 速度: 27.19秒/样本（含40%跳过检索优化）

---

## 🎯 预期结果

基于100样本测试，全数据集上的预期性能：

| 方法 | 预期EM | 预期F1 | 特点 |
|------|--------|--------|------|
| Self-Aware-MRAG | **62±1%** | **67±1%** | Adaptive+Attribution |
| Baselines平均 | **61±1%** | **69±1%** | 完整检索 |

**关键优势**:
1. ✅ EM超越baselines约+1%
2. ✅ F1接近baselines（-2%差距可接受）
3. ✅ 速度快40%（adaptive retrieval）
4. ✅ 独特的不确定性估计+归因能力

---

## 📝 待办事项

- [ ] 监控实验进度（每6小时检查一次）
- [ ] 实验完成后汇总结果
- [ ] 生成详细对比图表
- [ ] 更新GitHub仓库
- [ ] 撰写技术报告

---

**文档状态**: 🔄 实验进行中  
**更新时间**: 2025-10-31 12:05

