#!/usr/bin/env python3
"""
ä¸ºçº¯Wikipedia 3Mè¯­æ–™åº“é‡å»ºBGEç´¢å¼•
"""

import sys
from pathlib import Path

# æ·»åŠ FlashRAGè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from flashrag.retriever.index_builder import Index_Builder
from datasets import load_dataset
import argparse

def main():
    parser = argparse.ArgumentParser()
    parser.add_argument('--corpus', default='corpus/corpus_wiki_3m.jsonl', help='è¯­æ–™åº“è·¯å¾„')
    parser.add_argument('--output', default='indexes/wiki_3m/bge', help='è¾“å‡ºç›®å½•')
    parser.add_argument('--faiss-type', default='Flat', choices=['Flat', 'HNSW'], help='FAISSç´¢å¼•ç±»å‹')
    parser.add_argument('--batch-size', type=int, default=512, help='æ‰¹å¤„ç†å¤§å°')
    args = parser.parse_args()
    
    # è·¯å¾„è®¾ç½®
    corpus_path = Path(__file__).parent.parent / args.corpus
    output_dir = Path(__file__).parent.parent / args.output
    
    print("=" * 80)
    print("ä¸ºçº¯Wikipedia 3Mè¯­æ–™åº“æ„å»ºBGEç´¢å¼•")
    print("=" * 80)
    print(f"è¯­æ–™åº“: {corpus_path}")
    print(f"è¾“å‡ºç›®å½•: {output_dir}")
    print(f"ç´¢å¼•ç±»å‹: {args.faiss_type}")
    print("=" * 80)
    print()
    
    # æ£€æŸ¥è¯­æ–™åº“
    if not corpus_path.exists():
        print(f"âŒ é”™è¯¯: è¯­æ–™åº“æ–‡ä»¶ä¸å­˜åœ¨: {corpus_path}")
        sys.exit(1)
    
    # åŠ è½½è¯­æ–™åº“
    print("ğŸ“– åŠ è½½è¯­æ–™åº“...")
    corpus_dataset = load_dataset('json', data_files=str(corpus_path), split='train')
    print(f"âœ… è¯­æ–™åº“åŠ è½½æˆåŠŸ: {len(corpus_dataset):,} æ¡")
    print()
    
    # BGEé…ç½®
    model_path = "/root/autodl-tmp/models/bge-large-en-v1.5"
    bge_save_dir = output_dir
    bge_save_dir.mkdir(parents=True, exist_ok=True)
    
    bge_index_file = bge_save_dir / f"e5_{args.faiss_type}.index"
    bge_emb_file = bge_save_dir / f"emb_e5.memmap"
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
    if bge_index_file.exists() and bge_emb_file.exists():
        print(f"âš ï¸  BGEç´¢å¼•å·²å­˜åœ¨ï¼Œæ˜¯å¦è¦†ç›–ï¼Ÿ")
        print(f"   - ç´¢å¼•æ–‡ä»¶: {bge_index_file}")
        print(f"   - åµŒå…¥æ–‡ä»¶: {bge_emb_file}")
        response = input("è¾“å…¥ 'yes' ç»§ç»­è¦†ç›–ï¼Œæˆ–æŒ‰Enterè·³è¿‡: ")
        if response.lower() != 'yes':
            print("âœ… è·³è¿‡ç´¢å¼•æ„å»º")
            return
        print("âš ï¸  å°†è¦†ç›–ç°æœ‰ç´¢å¼•")
        print()
    
    # æ„å»ºBGEç´¢å¼•
    print("=" * 80)
    print("ğŸ”¨ æ„å»ºBGEæ–‡æœ¬ç´¢å¼•")
    print("=" * 80)
    print(f"æ¨¡å‹: {model_path}")
    print(f"è¯­æ–™åº“å¤§å°: {len(corpus_dataset):,} æ¡")
    print(f"æ‰¹å¤„ç†å¤§å°: {args.batch_size}")
    print()
    
    builder = Index_Builder(
        retrieval_method="e5",
        model_path=model_path,
        corpus_path=str(corpus_path),
        save_dir=str(bge_save_dir),
        max_length=512,
        batch_size=args.batch_size,
        use_fp16=True,
        pooling_method='cls',
        faiss_type=args.faiss_type
    )
    
    # å¼€å§‹æ„å»º
    print("å¼€å§‹æ„å»ºç´¢å¼•...")
    builder.build_index()
    
    # éªŒè¯è¾“å‡º
    print()
    print("=" * 80)
    print("âœ… ç´¢å¼•æ„å»ºå®Œæˆï¼")
    print("=" * 80)
    print(f"ç´¢å¼•æ–‡ä»¶: {bge_index_file}")
    print(f"  å¤§å°: {bge_index_file.stat().st_size / (1024**3):.2f} GB")
    print(f"åµŒå…¥æ–‡ä»¶: {bge_emb_file}")
    print(f"  å¤§å°: {bge_emb_file.stat().st_size / (1024**3):.2f} GB")
    print()

if __name__ == '__main__':
    main()
